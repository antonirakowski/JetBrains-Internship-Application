# üöÄ JetBrains Internship Application

## üß© Project Overview

This project is a web-based application that integrates biomedical data retrieval and clustering analysis. The core goals are:

1. **Data Fetching**: Retrieve GEO datasets related to user-provided PMIDs using NCBI's ELink and ESummary APIs.
2. **Clustering Model**: Group datasets based on textual features (title, experiment type, summary, and organism) using TF-IDF and clustering algorithms.
3. **User Interface**: Provide a clean, interactive, and user-friendly experience using a Flask web interface.

---

## üìÅ Project Structure

| File | Description |
|------|-------------|
| `model_creation.ipynb` | Jupyter notebook showcasing the complete modeling process, including experimentation, rationale, and results. |
| `model.py` | Script that runs the final model, clusters the data, and visualizes results using Plotly and NetworkX. |
| `api_call.py` | Script that fetches GEO dataset metadata (GEO IDs, titles, summaries, organisms, experiment types) based on provided PMIDs using NCBI APIs. |
| `app.py` | Flask application allowing users to input PMIDs or use a default list, fetch data, run the model, and display interactive visualizations. |

### ‚ö†Ô∏è **Important Notes:**

- `api_call.py` reads from a file called `PMIDs_list.txt`, which is automatically generated by `app.py` based on user input or a default list of PMIDs.  

- `api_call.py` fetches metadata and saves it into CSV files.  
  These files are essential for:
  - `model.py`.
  - `model_creation.ipynb`.

Thus, **make sure to run the Flask app (`app.py`) first** to generate all necessary files before executing the other scripts directly.
After running the app once, you're free to explore the outputs using the Python scripts or Jupyter notebook.

The specific tools, libraries, and frameworks used throughout the project are listed in the [`requirements.txt`](requirements.txt) file.

---

## ‚öôÔ∏è Setup Instructions

Before running the project for the first time, make sure to download the required NLTK and spaCy resources:

```python
import nltk
from spacy.cli import download

nltk.download("stopwords")
nltk.download("punkt")
download("en_core_web_sm")
